{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LGBIO2060_TP5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/svandergoote/LGBIO2060-2021/blob/Tp5/LGBIO2060_TP5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd-uRhH1cmSn"
      },
      "source": [
        "# LGBIO2060 Exercise session 5\n",
        "\n",
        "#Kalman filter\n",
        "\n",
        "__Authors:__ Simon Vandergooten, Clémence Vandamme\n",
        "\n",
        "__Content inspired from__: Neuromatch Academy github.com/NeuromatchAcademy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEi52Hd4c3OE"
      },
      "source": [
        "## Import and helper functions\n",
        "**Please execute the cell below to initialize the notebook environment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_He_4QlckhJ",
        "cellView": "form"
      },
      "source": [
        "#@title Imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from collections import namedtuple"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDxnOtZ78iG5",
        "cellView": "form"
      },
      "source": [
        "#@title Utility functions\n",
        "def plot_my_system(state_evolution):\n",
        "  \"\"\"\n",
        "  Do not edit this function...\n",
        "\n",
        "  the aim of this function is to represent the time-evolution of a dynamical linear system\n",
        "  Author : Antoine de Comite \n",
        "  \"\"\"\n",
        "  fig, ax = plt.subplots(figsize=(8,6))\n",
        "  xlim = None\n",
        "  ylim = None\n",
        "  ax.scatter(state_evolution[0,:],state_evolution[1,:],c='m',s=100,alpha=0.7)\n",
        "  ax.plot(state_evolution[0,:],state_evolution[1,:],LineWidth=2,c='k')\n",
        "  ax.set_xlabel(\"x_1\")\n",
        "  ax.set_ylabel(\"x_2\")\n",
        "  ax.set(xlim=xlim)\n",
        "  ax.set(ylim=ylim)\n",
        "  plt.plot()\n",
        "  return ax\n",
        "\n",
        "def plot_my_system_with_obs(state_evolution,obs_evolution):\n",
        "  \"\"\"\n",
        "  Do not edit this function...\n",
        "\n",
        "  the aim of this function is to represent the time-evolution of a dynamical linear system\n",
        "  Author : Antoine de Comite \n",
        "  \"\"\"\n",
        "  fig, ax = plt.subplots(figsize=(8,6))\n",
        "  xlim = None\n",
        "  ylim = None\n",
        "  ax.scatter(state_evolution[0,:],state_evolution[1,:],c='m',s=100,alpha=0.7)\n",
        "  ax.plot(state_evolution[0,:],state_evolution[1,:],LineWidth=2,c='k',label='Latent state')\n",
        "  ax.plot(obs_evolution[0,:],obs_evolution[1,:],LineWidth=2,c='g',label='Observation')\n",
        "  ax.set_xlabel(\"x_1\")\n",
        "  ax.set_ylabel(\"x_2\")\n",
        "  ax.set(xlim=xlim)\n",
        "  ax.set(ylim=ylim)\n",
        "  ax.legend()\n",
        "  plt.plot()\n",
        "  return ax\n",
        "\n",
        "def plot_my_kalman_filter(state_evolution,obs_evolution,estimated_evolution):\n",
        "  \"\"\"\n",
        "  DO NOT EDIT THIS FUNCTION\n",
        "  author : antoine de Comite \n",
        "  \"\"\"\n",
        "\n",
        "  fig,ax = plt.subplots(figsize=(8,6))\n",
        "  xlim = None; ylim = None\n",
        "  ax.scatter(state_evolution[0,:-1],state_evolution[1,:-1],c='m',s=100,alpha=0.7)\n",
        "  ax.plot(state_evolution[0,:-1],state_evolution[1,:-1],LineWidth=2,c='k',label='Latent state')\n",
        "  ax.plot(obs_evolution[0,:-1],obs_evolution[1,:-1],LineWidth=2,c='g',label='Observation')\n",
        "  ax.plot(estimated_evolution[0,:-1],obs_evolution[1,:-1],LineWidth=2,c='r',label='Estimation')\n",
        "  ax.set_xlabel(\"x_1\")\n",
        "  ax.set_ylabel(\"x_2\")\n",
        "  ax.set(xlim=xlim)\n",
        "  ax.set(ylim=ylim)\n",
        "  ax.legend()\n",
        "  plt.plot()\n",
        "  return ax\n",
        "\n",
        "\n",
        "gaussian = namedtuple('Gaussian', ['mean', 'cov'])\n",
        "def filter(D, process_noise, measurement_noise, posterior, m):\n",
        "    todays_prior = gaussian(D * posterior.mean, D**2 * posterior.cov + process_noise)\n",
        "    likelihood = gaussian(m, measurement_noise)\n",
        "\n",
        "    info_prior = 1/todays_prior.cov\n",
        "    info_likelihood = 1/likelihood.cov\n",
        "    info_posterior = info_prior + info_likelihood\n",
        "\n",
        "    prior_weight = info_prior / info_posterior\n",
        "    likelihood_weight = info_likelihood / info_posterior\n",
        "    posterior_mean = prior_weight * todays_prior.mean  +  likelihood_weight * likelihood.mean\n",
        "\n",
        "    posterior_cov = 1/info_posterior\n",
        "    todays_posterior = gaussian(posterior_mean, posterior_cov)\n",
        "    \"\"\"\n",
        "    prior = gaussian(belief.mean, belief.cov)\n",
        "\n",
        "    predicted_estimate = D * belief.mean\n",
        "    predicted_covariance = D**2 * belief.cov + process_noise\n",
        "\n",
        "    likelihood = gaussian(m, measurement_noise)\n",
        "    innovation_estimate = m - predicted_estimate\n",
        "    innovation_covariance = predicted_covariance + measurement_noise\n",
        "\n",
        "    K = predicted_covariance / innovation_covariance  # Kalman gain, i.e. the weight given to the difference between the measurement and predicted measurement\n",
        "    updated_mean = predicted_estimate + K * innovation_estimate\n",
        "    updated_cov = (1 - K) * predicted_covariance\n",
        "    todays_posterior = gaussian(updated_mean, updated_cov)\n",
        "    \"\"\"\n",
        "    return todays_prior, likelihood, todays_posterior\n",
        "\n",
        "def paintMyFilter(D, initial_guess, process_noise, measurement_noise, s, m, s_, cov_):\n",
        "    # Compare solution with filter function\n",
        "    T = 50\n",
        "    t = np.arange(0, T, 1)\n",
        "    filter_s_ = np.zeros(T)    # estimate (posterior mean)\n",
        "    filter_cov_ = np.zeros(T)    # uncertainty (posterior covariance)\n",
        "\n",
        "    filter_s_ = s_\n",
        "    filter_cov_ = cov_\n",
        "    posterior = initial_guess\n",
        "    filter_s_[0] = posterior.mean\n",
        "    filter_cov_[0] = posterior.cov\n",
        "\n",
        "    process_noise_std = np.sqrt(process_noise)\n",
        "    measurement_noise_std = np.sqrt(measurement_noise)\n",
        "\n",
        "    for i in range(1, T):\n",
        "        prior, likelihood, posterior = filter(D, process_noise, measurement_noise, posterior, m[i])\n",
        "        filter_s_[i] =  posterior.mean\n",
        "        filter_cov_[i] = posterior.cov\n",
        "\n",
        "    smin = min(min(m),min(s-2*np.sqrt(cov_[-1])),min(s_-2*np.sqrt(cov_[-1])))\n",
        "    smax = max(max(m),max(s+2*np.sqrt(cov_[-1])),max(s_+2*np.sqrt(cov_[-1])))\n",
        "    pscale = 0.2  # scaling factor for displaying pdfs\n",
        "\n",
        "    fig = plt.figure(figsize=[15, 10])\n",
        "    ax = plt.subplot(2, 1, 1)\n",
        "    ax.set_xlabel('time')\n",
        "    ax.set_ylabel('state')\n",
        "    ax.set_xlim([0, T+(T*pscale)])\n",
        "    ax.set_ylim([smin, smax])\n",
        "\n",
        "    ax.plot(t, s, color='limegreen', lw=2, label='Fly´s trajectory')\n",
        "    ax.plot([t[-1]], [s[-1]], marker='o', markersize=8, color='limegreen')\n",
        "\n",
        "    ax.plot(t, m, '.', color='crimson', lw=2, label='measurements')\n",
        "    ax.plot([t[-1]], [m[-1]], marker='o', markersize=8, color='crimson')\n",
        "\n",
        "    ax.plot(t, filter_s_, color='black', lw=2, label='correct estimated trajectory')\n",
        "    ax.plot([t[-1]], [filter_s_[-1]], marker='o', markersize=8, color='black')\n",
        "\n",
        "    res = '! :)' if np.mean((s_ - filter_s_)**2) < 0.1 else ' :('\n",
        "    ax.plot(t, s_, '--', color='lightgray', lw=2, label='your estimated trajectory' + res)\n",
        "    ax.plot([t[-1]], [s_[-1]], marker='o', markersize=8, color='lightgray')\n",
        "\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "import ipywidgets as widgets  # interactive display\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "# use NMA plot style\n",
        "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/nma.mplstyle\")\n",
        "my_layout = widgets.Layout()\n",
        "\n",
        "def my_system_with_obs1D(nsteps,x0,A,H,omega_motor,omega_sensory):\n",
        "  \"\"\"\n",
        "  my_system_with_obs is a function that model the time-evolution of the latent state \n",
        "  and its observation\n",
        "  Inputs : nsteps is the number of time steps to model\n",
        "           x0 is the initial state (where we are starting from)\n",
        "           A is the state-transition matrix\n",
        "           H is the observation matrix\n",
        "           omega_motor is the variance of the motor noise\n",
        "           sigma_sensory is the variance of the sensory noise\n",
        "  Outputs : state_evolution is a numpy array that contains the time-evolution of \n",
        "            the state vector : (state size * nsteps)\n",
        "            obs_evolution is a numpy array that contains the time-evolution of \n",
        "            the observation of the state vector : (state size * nsteps)\n",
        "  \"\"\"\n",
        "  ######################\n",
        "  ### your code here ###\n",
        "  ######################\n",
        "  state_evolution = my_system1D(nsteps, x0, A, omega_motor)\n",
        "\n",
        "  \n",
        "  obs_evolution = np.zeros(nsteps)\n",
        "  for step in range(nsteps):\n",
        "    noise = np.random.normal(0, np.sqrt(omega_sensory))\n",
        "    obs_evolution[step] = H * state_evolution[step] + noise\n",
        "    \n",
        "  return state_evolution,obs_evolution\n",
        "\n",
        "def my_system1D(nsteps,x0,A,omega_motor,seed=2060):\n",
        "  \"\"\"\n",
        "  my_system is a function that model the time-evolution of a linear dynamical system\n",
        "  with state transition matrix A.\n",
        "  Inputs : nsteps is the number of time steps to model\n",
        "           x0 is the initial state (where we are starting from)\n",
        "           A is the state-transition matrix\n",
        "           omega_motor is the covariance matrix\n",
        "  Outputs : state_evolution is a numpy array that contains the time-evolution of \n",
        "            the state vector : (state size * nsteps)\n",
        "  \"\"\"\n",
        "  # Set the random generator seed\n",
        "  np.random.seed(seed)\n",
        "\n",
        "  ########################\n",
        "  #### Your code here ####\n",
        "  ########################\n",
        "  \n",
        "  state_evolution = np.zeros(nsteps)\n",
        "  state_evolution[0] = x0\n",
        "\n",
        "  means = np.zeros(1)\n",
        "  for step in range(1,nsteps):\n",
        "    noise = np.random.normal(means, np.sqrt(omega_motor))\n",
        "    state_evolution[step] = A * state_evolution[step-1] + noise\n",
        "\n",
        "  return state_evolution"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYDwDdw8eMLJ"
      },
      "source": [
        "#Introduction\n",
        "In this tutorial, you will estimate the true state of a continuous variable. Like in the last session, this state evolves over time. Therefore, at each time step you will use both your prior knowledge (consisting of the previous estimate and the system dynamics) and a new measurement. The continuous adaptation of the Bayes theorem on dynamical sytems is called a *Kalman filter*. \n",
        "\n",
        "\n",
        "## Dynamical systems\n",
        "\n",
        "Like in Hidden Markov Models, one state only depends on the previous state, the past history does not matter. \n",
        "\n",
        "In one dimension, you have the following relationship: \n",
        "\n",
        "\\begin{eqnarray}\n",
        "& & \\\\\n",
        "x\\left[t+1\\right] & = & a x\\left[t\\right] + \\xi\\left[t\\right] \\\\\n",
        "& & \\\\\n",
        "\\end{eqnarray}\n",
        "\n",
        "Where $a$ is a deterministic known parameter and $\\xi$ is gaussian motor noise generated from $\\mathcal{N}\\left(0,\\sigma^2\\right)$. \n",
        "\n",
        "You can easily extend this description to 2 (or more) dimensions with a matrix representation (for example to estimate a position in x- and y- dimension): \n",
        "\n",
        "\\begin{eqnarray}\n",
        "&&\\\\\n",
        "\\begin{bmatrix}\n",
        "  x_1[t+1] \\\\\n",
        "  x_2[t+1]\n",
        "  \\end{bmatrix} &=& \\begin{bmatrix}A_{11} & A_{12}\\\\ A_{21} & A_{22} \\end{bmatrix}\\begin{bmatrix}x_1[t]\\\\ x_2[t]\\end{bmatrix} + \\begin{bmatrix}\\xi_1[t] \\\\ \\xi_2[t] \\end{bmatrix}\n",
        "  &&\\\\\n",
        "\\end{eqnarray}\n",
        "\n",
        "\\\\\n",
        "\n",
        "**Exercise - Implement a function that defines the system mentionned above**\n",
        "\n",
        "In this first exercise, you are asked to model the dynamical system characterised by the equation above. \n",
        "\n",
        "Hints : \n",
        "* You will be performing matrix multiplications, consider this while implementing your function...\n",
        "\n",
        "* See the function np.random.multivariate_normal to generate noise for multiple variables\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ATpdHNNn-5i"
      },
      "source": [
        "def my_system(nsteps, x0, A, omega_motor, seed=2060):\n",
        "  \"\"\"\n",
        "  my_system is a function that model the time-evolution of a linear dynamical system\n",
        "  with state transition matrix A.\n",
        "  Inputs : nsteps is the number of time steps to model\n",
        "           x0 is the initial state (where we are starting from)\n",
        "           A is the state-transition matrix\n",
        "           omega_motor is the covariance matrix\n",
        "  Outputs : state_evolution is a numpy array that contains the time-evolution of \n",
        "            the state vector : (state size, nsteps)\n",
        "  \"\"\"\n",
        "  # Set the random generator seed\n",
        "  np.random.seed(seed)\n",
        "\n",
        "  ########################\n",
        "  #### Your code here ####\n",
        "  ########################\n",
        "\n",
        "  return state_evolution\n",
        "\n",
        "# Run the lines below to test your code\n",
        "\n",
        "nsteps = 50\n",
        "x0 = np.array([1,1]).T\n",
        "A = np.array([[1., 1.], [-(2*np.pi/20.)**2., .9]])\n",
        "sigma_motor = 0.05\n",
        "omega_motor = [[sigma_motor , 0],[0, sigma_motor]]\n",
        "\n",
        "state_evolution = my_system(nsteps,x0,A,omega_motor)\n",
        "plot_my_system(state_evolution)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mz1vFOB-XWl"
      },
      "source": [
        "*Example output:*\n",
        "\n",
        "<img alt='Solution hint' align='left' width=413 height=300 src=https://raw.githubusercontent.com/svandergoote/LGBIO2060-2021/master/Solutions/TP5_ex1.PNG>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nQ__9qRFBLA"
      },
      "source": [
        "**What is the effect of the motor noise covariance on the behaviour of the system?**\n",
        "\n",
        "\n",
        "Play with the widget below to explore this effect. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFwCNuwDArt4",
        "cellView": "form"
      },
      "source": [
        "# @title\n",
        "# @markdown Make sure you execute this cell to enable the widget!\n",
        "my_layout.width = '450px'\n",
        "@widgets.interact(\n",
        "    sigma_motor=widgets.FloatSlider(0.05, min=0, max=1, step=0.05, layout=my_layout)\n",
        "\n",
        ")\n",
        "\n",
        "def sigma_motor(sigma_motor = 0.05):\n",
        "    nsteps = 50\n",
        "    x0 = np.array([1,1]).T\n",
        "    A = np.array([[1., 1.], [-(2*np.pi/20.)**2., .9]])\n",
        "    omega_motor = [[sigma_motor , 0],[0, sigma_motor]]\n",
        "    state_evolution = my_system(nsteps,x0,A,omega_motor)\n",
        "    plot_my_system(state_evolution)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "064vvCvAFyQB"
      },
      "source": [
        "---\n",
        "##Imperfect measurements\n",
        "\n",
        "As we saw in the previous tutorials, our sensory inputs are not perfect and it is impossible to know the real latent state; we can only get a rough estimate of it. Mathematically, we define the observation of the latent state of our dynamical system, $y[t]$ as follows: \n",
        "\n",
        "\n",
        "$\\begin{eqnarray}\n",
        "& & \\\\\n",
        "y[t]& = & H x[t] + \\eta[t]\\\\\n",
        " & & \\\\\n",
        "\\begin{bmatrix}y_1[t]\\\\ y_2[t]\\end{bmatrix} & = &\\begin{bmatrix}1 & 0 \\\\ 0 & 1\\end{bmatrix} \\begin{bmatrix}x_1[t] \\\\ x_2[t]\\end{bmatrix} + \\begin{bmatrix}\\eta_1[t]\\\\ \\eta_2[t]\\end{bmatrix}\n",
        "& &\\\\\n",
        "\\end{eqnarray}$\n",
        "\n",
        "where $H$ is the called the *observation matrix* and $\\eta[t]$ is a vector of Gaussian white sensory noise generated from $\\mathcal{N}\\left(0,\\Omega_{\\text{sensory}}\\right)$. \n",
        "\n",
        "**Exercise - Implement the observation of the latent state**\n",
        "\n",
        "You will implement a function which simulates first the true state evolution (use the function `my_system`), then takes noisy measurement of these states according to the above relationship. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEScQ4Geoz08"
      },
      "source": [
        "def my_system_with_obs(nsteps,x0,A,H,omega_motor,omega_sensory):\n",
        "  \"\"\"\n",
        "  my_system_with_obs is a function that model the time-evolution of the latent state \n",
        "  and its observation\n",
        "  Inputs : nsteps is the number of time steps to model\n",
        "           x0 is the initial state (where we are starting from)\n",
        "           A is the state-transition matrix\n",
        "           H is the observation matrix\n",
        "           omega_motor is the variance of the motor noise\n",
        "           sigma_sensory is the variance of the sensory noise\n",
        "  Outputs : state_evolution is a numpy array that contains the time-evolution of \n",
        "            the state vector : (state size, nsteps)\n",
        "            obs_evolution is a numpy array that contains the time-evolution of \n",
        "            the observation of the state vector : (state size, nsteps)\n",
        "  \"\"\"\n",
        "  ######################\n",
        "  ### your code here ###\n",
        "  ######################\n",
        "  \n",
        "  return state_evolution,obs_evolution\n",
        "\n",
        "# Run the lines below to test your code \n",
        "np.random.seed(2060)\n",
        "nsteps = 50\n",
        "x0 = np.array([1,1]).T\n",
        "A = np.array([[1.,1.],[-(2*np.pi/20.)**2.,0.9]])\n",
        "H = np.eye(2)\n",
        "sigma_motor = 0.05\n",
        "sigma_sensory_x = 0.02\n",
        "sigma_sensory_y = 0.03\n",
        "omega_motor = [[sigma_motor , 0],[0, sigma_motor]]\n",
        "omega_sensory = [[sigma_sensory_x , 0],[0, sigma_sensory_y]]\n",
        "\n",
        "state_evolution, obs_evolution = my_system_with_obs(nsteps, x0, A, H, omega_motor, omega_sensory)\n",
        "plot_my_system_with_obs(state_evolution,obs_evolution)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8UtFShu_v0J"
      },
      "source": [
        "*Example output:*\n",
        "\n",
        "<img alt='Solution hint' align='left' width=413 height=300 src=https://raw.githubusercontent.com/svandergoote/LGBIO2060-2021/master/Solutions/TP5_ex2.PNG>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "embb74sbOnq7"
      },
      "source": [
        "The green line, corresponding to the measurements, will be used to build your likelihood. To give you more intuition about the meaning of this likelihood, you will implement a simple function `compare` to compare measurements to the values.\n",
        "\n",
        "You will then call this 1D function on both variables of the system.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cysTy_5hJIB2"
      },
      "source": [
        "def compare(s, m):\n",
        "  \"\"\" Compute a scatter plot\n",
        "\n",
        "  Args:\n",
        "    s (ndarray): astrocat's true position over time\n",
        "    m (ndarray): astrocat's measured position over time according to the sensor\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_subplot(111)\n",
        "  sbounds = 1.1*max(max(np.abs(s)), max(np.abs(m)))\n",
        "  ax.plot([-sbounds, sbounds], [-sbounds, sbounds], 'k')    # plot line of equality\n",
        "  ax.set_xlabel('state')\n",
        "  ax.set_ylabel('measurement')\n",
        "  ax.set_aspect('equal')\n",
        "\n",
        "  # Complete a scatter plot: true state versus measurements\n",
        "  #### YOUR CODE HERE ####\n",
        "\n",
        "\n",
        "# Visualize true vs measured states (use state_evolution and state_obs from last cell)\n",
        "\n",
        "#### YOUR CODE HERE ####\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMV7buBNxZoj"
      },
      "source": [
        "##Kalman filter, or the optimal estimation of continuous linear dynamical systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKT61go4IfYT"
      },
      "source": [
        "A Kalman filter estimates a posterior probability distribution *recursively* over time using a mathematical model of the process and incoming measurements. This dynamic posterior allows us to improve our guess about the fly's position as new measures arrive. Then the posterior's mean is the best estimate one can compute of fly's actual position at each time step.\n",
        "\n",
        "Now it's your turn! Follow this recipe to complete the code below and implement your own Kalman filter. To make things easier, we will first only consider a 1D system.   \n",
        "\n",
        "**Step 1: Change yesterday's posterior into today's prior** \n",
        "\n",
        "The first step consists into updating yesterday's posterior into today's prior while taking into account the system dynamics. Recall that yesterday's posterior is a gaussian distribution $\\mathcal{N}(\\mu_{s_{t-1}}, \\sigma_{s_{t-1}}^2)$. The mathematical model of the system is composed of a deterministic shift $a$ and some additional noise. \n",
        "-  When you multiply your prior by $a$, you multiply each point of the distribution. Therefore, you will get a new distribution:  $$\\mathcal{N}(a*\\mu_{s_{t-1}}, a^2*\\sigma_{s_{t-1}}^2)$$\n",
        "\n",
        "- Then, you add the process noise and get: $$\\mathcal{N}(a*\\mu_{s_{t-1}}, a^2*\\sigma_{s_{t-1}}^2 + \\sigma_{motor}^2)$$\n",
        "\n",
        "You have now today's prior ! \n",
        "\n",
        "**Step 2: Multiply today's prior by likelihood** \n",
        "\n",
        "Use the latest measurement  to form a new estimate somewhere between this measurement and what we predicted in Step 1. The next posterior is the result of multiplying the Gaussian computed in Step 1 (a.k.a. today's prior) and the likelihood, which is also modeled as a Gaussian $\\mathcal{N}(m_t, \\sigma_{sensory}^2)$:\n",
        "\n",
        "**2a: add information from prior and likelihood** \n",
        "\n",
        "To find the posterior variance, we first compute the posterior information (which is the inverse of the variance) by adding the information provided by the prior and the likelihood:\n",
        "\n",
        "> $\\frac{1}{\\sigma_{s_t}^2} = \\frac{1}{a^2*\\sigma_{s_{t-1}}^2 + \\sigma_{motor}^2} + \\frac{1}{\\sigma_{sensory}^2} $\n",
        "\n",
        "Now we can take the inverse of the posterior information to get back the posterior variance.\n",
        "\n",
        "**2b: add means from prior and likelihood** \n",
        "\n",
        "To find the posterior mean, we calculate a weighted average of means from prior and likelihood, where each weight, $g$, is just the fraction of information that each Gaussian provides!\n",
        "\n",
        "> $g_{\\rm{prior}} = \\frac{\\rm{information}_{\\textit{ }\\rm{prior}}}{\\rm{information}_{\\textit{ }\\rm{posterior}}}$\n",
        ">\n",
        "> $g_{\\rm{likelihood}} = \\frac{\\rm{information}_{\\textit{ }\\rm{likelihood}}}{\\rm{information}_{\\textit{ }\\rm{posterior}}}$\n",
        ">\n",
        "> $\\bar{\\mu}_t = g_{\\rm{prior}}* a*\\mu_{s_{t-1}} + g_{\\rm{likelihood}}* m_t$ \n",
        "    \n",
        "\n",
        "**Implementation detail:** \n",
        "Recall that the best estimate is the mean of the posterior distribution and the associated variance can be computed based on the information of the prior and the likelihood.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQXKcx3bcR-H"
      },
      "source": [
        "def Kalman_filter_1D(x0, M, a, sigma_start, sigma_motor, sigma_sensory):\n",
        "  \"\"\"\n",
        "  my_kalman_filter computes and applies the Kalman filter to the system seen above\n",
        "  Inputs : x0 is the initial state (where we are starting from)\n",
        "           M is the vector of measurements (no measurement on the initial state)\n",
        "           a is the deterministic parameter of the system\n",
        "           sigma_start is the variance associated with the initial state\n",
        "           sigma_motor is the variance of the noise of the system\n",
        "           sigma_sensory is the variance of the noise on the measurement\n",
        "  Outputs : estimated_state is a numpy array that contains the time-evolution of \n",
        "              the estimation of the state vector\n",
        "            estimates_cov is a numpy array that contains the uncertainty \n",
        "              (variance) associated with your posterior estimates\n",
        "  \"\"\"\n",
        "  ##########################\n",
        "  ##### Your code here #####\n",
        "  ##########################\n",
        "  \n",
        "\n",
        "  return estimated_state, estimates_cov\n",
        "\n",
        "#Parameters\n",
        "omega_motor = 0.05\n",
        "omega_sensory = 0.02\n",
        "omega_start = omega_sensory\n",
        "x0 = 0.0\n",
        "a = 0.8\n",
        "nsteps = 50\n",
        "H = 1\n",
        "\n",
        "#Call the functions\n",
        "true_states, M = my_system_with_obs1D(nsteps, x0, a, H, omega_motor, omega_sensory)\n",
        "estimate, cov = Kalman_filter_1D(x0, M, a, omega_start, omega_motor, omega_sensory)\n",
        "\n",
        "#Create distributions\n",
        "x0_distr = gaussian(0, omega_motor/(1-a**2))\n",
        "\n",
        "paintMyFilter(a, x0_distr, omega_motor, omega_sensory, true_states, M, estimate, cov)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5TK6EpzjGz4"
      },
      "source": [
        "*Example output:*\n",
        "\n",
        "<img alt='Solution hint' align='left' width=900 height=300 src=https://raw.githubusercontent.com/svandergoote/LGBIO2060-2021/master/Solutions/TP5_ex3.PNG>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCYFi03HcQl1"
      },
      "source": [
        "**Relationship to classic description of Kalman filter:**\n",
        "\n",
        "We're teaching this recipe because it is interpretable and connects to past lessons about the bayesian inference. But the classic description of the Kalman filter is a little different. The above weights, $g_{\\rm{prior}}$ and $g_{\\rm{likelihood}}$, add up to $1$ and can be written one in terms of the other; then, if we define the Kalman gain $K = g_{\\rm{likelihood}}$, then $g_{\\rm{prior}} = 1-K$. \n",
        "\n",
        "In classic textbooks, you will often find the following expression: \n",
        "\n",
        "$\\begin{eqnarray}\n",
        "& & \\\\\n",
        "\\hat{x}[t+1] & = & A  \\hat{x}[t]+ K[t]\\left(y[t] - H \\hat{x}[t]\\right)\\\\\n",
        "& & \\\\\n",
        "\\end{eqnarray}$\n",
        "\n",
        "\n",
        "Where $K[t]$ is the Kalman gain evaluated at time $t$. These Kalman gains will be the weighting parameters that characterises how much we trust one source of information (prior and likelihood) over the other. Since these gains quantifies the trust we have in each source, they will be computed based on the covariances matrices of these two sources. The covariance matrix related to the prior is $\\Omega_{\\text{motor}}$ and the one related to the likelihood is $\\Omega_{\\text{sensory}}$. Therefore the gain of the kalman filter are recursively computed as follows:  \n",
        "\n",
        "$\\begin{eqnarray}\n",
        "& & \\\\\n",
        "K[t]& = &A\\, \\Sigma[t] \\,H^T \\left(H \\,\\Sigma[T]\\,H^T+\\Omega_{\\text{motor}}\\right)^{-1} \\\\\n",
        "& & \\\\\n",
        "\\Sigma[t+1] & = & \\Omega_{\\text{sensory}} + \\left(A-K[t]\\,H\\right)\\Sigma[T]\\,A^T\n",
        "\\end{eqnarray}$\n",
        "\n",
        "Where $\\Sigma[t] = \\mathbb{C}\\text{ov}\\left\\{\\hat{x}[t]\\right\\}$ is the covariance matrix of the estimated state at time t. \n",
        "\n",
        "\n",
        "**Exercice - Implement the function below to apply Kalman filter in 2D to the dynamical linear system**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB-W0jY-87UU"
      },
      "source": [
        "def my_kalman_filter(nsteps,x0,A,H,omega_motor,omega_sensory,seed=2060):\n",
        "  \"\"\"\n",
        "  my_kalman_filter computes and applies the Kalman filter to the system seen above\n",
        "  Inputs : nsteps is the number of time steps to model\n",
        "           x0 is the initial state (where we are starting from)\n",
        "           A is the state-transition matrix\n",
        "           H is the observation matrix\n",
        "  Outputs : latent_state is a numpy array that contains the time-evolution of \n",
        "             the state vector : (state size * nsteps)\n",
        "            observed_state is a numpy array that contains the time-evolution of \n",
        "             the observation of the state vector : (state size * nsteps)\n",
        "            estimated_state is a numpy array that contains the time-evolution of \n",
        "              the estimation of the state vector : (state size * nsteps)\n",
        "            K kalman gains: (state size * state size * nsteps)\n",
        "  \"\"\"\n",
        "  np.random.seed(seed)\n",
        "\n",
        "  K = np.zeros((len(x0),len(x0),nsteps))\n",
        "  Sigma = np.zeros((len(x0),len(x0),nsteps))\n",
        "\n",
        "  ####################\n",
        "  ## your code here ##\n",
        "  ####################\n",
        "  return latent_state,observed_state, estimated_state, K\n",
        "\n",
        "\n",
        "# Run the lines below to test your code\n",
        "\n",
        "# Parameters definition\n",
        "nsteps = 50\n",
        "A = np.array([[1.,1.],[-(2*np.pi/20.)**2.,0.9]])\n",
        "H = np.eye(2)\n",
        "x0 = np.array([1,1]).T\n",
        "omega_motor = 0.05 * np.eye(len(x0))\n",
        "omega_sensory = 0.02 * np.eye(len(x0))\n",
        "\n",
        "####################\n",
        "## your code here ##\n",
        "####################\n",
        "\n",
        "plot_my_kalman_filter(state_evolution, obs_evolution, estimated_evolution)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG0ae8od_2Ee"
      },
      "source": [
        "*Example output:*\n",
        "\n",
        "<img alt='Solution hint' align='left' width=413 height=300 src=https://raw.githubusercontent.com/fblondiaux/LGBIO2060-2020/master/Solutions/TP3-Ex3.png>"
      ]
    }
  ]
}